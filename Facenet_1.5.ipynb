{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow==1.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/unreal/anaconda3/envs/1.5_tf/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/unreal/anaconda3/envs/1.5_tf/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/unreal/anaconda3/envs/1.5_tf/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/unreal/anaconda3/envs/1.5_tf/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/unreal/anaconda3/envs/1.5_tf/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/unreal/anaconda3/envs/1.5_tf/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from yacs.config import CfgNode as CN\n",
    "\n",
    "from scipy import misc\n",
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "from time import sleep\n",
    "\n",
    "from subprocess import Popen, PIPE\n",
    "from scipy import misc\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy import interpolate\n",
    "from tensorflow.python.training import training\n",
    "import re\n",
    "from tensorflow.python.platform import gfile\n",
    "import math\n",
    "from six import iteritems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget http://vis-www.cs.umass.edu/lfw/lfw.tgz -O Datasets/lfw.tgz\n",
    "# !mkdir -p Datasets/lfw/raw\n",
    "# !tar -xvf Datasets/lfw.tgz -C Datasets/lfw/raw --strip-components=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Facenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "code_folding": [
     0,
     19,
     33,
     40,
     45,
     54,
     57,
     91,
     93,
     118,
     144,
     161,
     167,
     178,
     179,
     182,
     187,
     200,
     211,
     222,
     229,
     244,
     253,
     267,
     273,
     294,
     297,
     317,
     340,
     355,
     387,
     398,
     410,
     433,
     442,
     468,
     473,
     486,
     489
    ]
   },
   "outputs": [],
   "source": [
    "def triplet_loss(anchor, positive, negative, alpha):\n",
    "    \"\"\"Calculate the triplet loss according to the FaceNet paper\n",
    "    \n",
    "    Args:\n",
    "      anchor: the embeddings for the anchor images.\n",
    "      positive: the embeddings for the positive images.\n",
    "      negative: the embeddings for the negative images.\n",
    "  \n",
    "    Returns:\n",
    "      the triplet loss according to the FaceNet paper as a float tensor.\n",
    "    \"\"\"\n",
    "    with tf.variable_scope('triplet_loss'):\n",
    "        pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, positive)), 1)\n",
    "        neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, negative)), 1)\n",
    "        \n",
    "        basic_loss = tf.add(tf.subtract(pos_dist,neg_dist), alpha)\n",
    "        loss = tf.reduce_mean(tf.maximum(basic_loss, 0.0), 0)\n",
    "      \n",
    "    return loss  \n",
    "def center_loss(features, label, alfa, nrof_classes):\n",
    "    \"\"\"Center loss based on the paper \"A Discriminative Feature Learning Approach for Deep Face Recognition\"\n",
    "       (http://ydwen.github.io/papers/WenECCV16.pdf)\n",
    "    \"\"\"\n",
    "    nrof_features = features.get_shape()[1]\n",
    "    centers = tf.get_variable('centers', [nrof_classes, nrof_features], dtype=tf.float32,\n",
    "        initializer=tf.constant_initializer(0), trainable=False)\n",
    "    label = tf.reshape(label, [-1])\n",
    "    centers_batch = tf.gather(centers, label)\n",
    "    diff = (1 - alfa) * (centers_batch - features)\n",
    "    centers = tf.scatter_sub(centers, label, diff)\n",
    "    with tf.control_dependencies([centers]):\n",
    "        loss = tf.reduce_mean(tf.square(features - centers_batch))\n",
    "    return loss, centers\n",
    "def get_image_paths_and_labels(dataset):\n",
    "    image_paths_flat = []\n",
    "    labels_flat = []\n",
    "    for i in range(len(dataset)):\n",
    "        image_paths_flat += dataset[i].image_paths\n",
    "        labels_flat += [i] * len(dataset[i].image_paths)\n",
    "    return image_paths_flat, labels_flat\n",
    "def shuffle_examples(image_paths, labels):\n",
    "    shuffle_list = list(zip(image_paths, labels))\n",
    "    random.shuffle(shuffle_list)\n",
    "    image_paths_shuff, labels_shuff = zip(*shuffle_list)\n",
    "    return image_paths_shuff, labels_shuff\n",
    "def random_rotate_image(image):\n",
    "    angle = np.random.uniform(low=-10.0, high=10.0)\n",
    "    return misc.imrotate(image, angle, 'bicubic')\n",
    "# 1: Random rotate 2: Random crop  4: Random flip  8:  Fixed image standardization  16: Flip\n",
    "RANDOM_ROTATE = 1\n",
    "RANDOM_CROP = 2\n",
    "RANDOM_FLIP = 4\n",
    "FIXED_STANDARDIZATION = 8\n",
    "FLIP = 16\n",
    "def create_input_pipeline(input_queue, image_size, nrof_preprocess_threads, batch_size_placeholder):\n",
    "    with tf.name_scope(\"tempscope\"):    \n",
    "        images_and_labels_list = []\n",
    "        for _ in range(nrof_preprocess_threads):\n",
    "            filenames, label, control = input_queue.dequeue()\n",
    "            images = []\n",
    "            for filename in tf.unstack(filenames):\n",
    "                file_contents = tf.read_file(filename)\n",
    "                image = tf.image.decode_image(file_contents, 3)\n",
    "                image = tf.cond(get_control_flag(control[0], RANDOM_ROTATE),\n",
    "                                lambda:tf.py_func(random_rotate_image, [image], tf.uint8), \n",
    "                                lambda:tf.identity(image))\n",
    "                image = tf.cond(get_control_flag(control[0], RANDOM_CROP), \n",
    "                                lambda:tf.random_crop(image, image_size + (3,)), \n",
    "                                lambda:tf.image.resize_image_with_crop_or_pad(image, image_size[0], image_size[1]))\n",
    "                image = tf.cond(get_control_flag(control[0], RANDOM_FLIP),\n",
    "                                lambda:tf.image.random_flip_left_right(image),\n",
    "                                lambda:tf.identity(image))\n",
    "                image = tf.cast(image, tf.float32)\n",
    "                image = tf.cond(get_control_flag(control[0], FIXED_STANDARDIZATION),\n",
    "                                lambda:(tf.cast(image, tf.float32) - 127.5)/128.0,\n",
    "                                lambda:tf.image.per_image_standardization(image))\n",
    "                image = tf.cond(get_control_flag(control[0], FLIP),\n",
    "                                lambda:tf.image.flip_left_right(image),\n",
    "                                lambda:tf.identity(image))\n",
    "                #pylint: disable=no-member\n",
    "                image.set_shape(image_size + (3,))\n",
    "                images.append(image)\n",
    "            images_and_labels_list.append([images, label])\n",
    "\n",
    "        image_batch, label_batch = tf.train.batch_join(\n",
    "            images_and_labels_list, batch_size=batch_size_placeholder, \n",
    "            shapes=[image_size + (3,), ()], enqueue_many=True,\n",
    "            capacity=4 * nrof_preprocess_threads * 100,\n",
    "            allow_smaller_final_batch=True)\n",
    "\n",
    "        return image_batch, label_batch\n",
    "def get_control_flag(control, field):\n",
    "    return tf.equal(tf.mod(tf.floor_div(control, field), 2), 1)\n",
    "def _add_loss_summaries(total_loss):\n",
    "    \"\"\"Add summaries for losses.\n",
    "  \n",
    "    Generates moving average for all losses and associated summaries for\n",
    "    visualizing the performance of the network.\n",
    "  \n",
    "    Args:\n",
    "      total_loss: Total loss from loss().\n",
    "    Returns:\n",
    "      loss_averages_op: op for generating moving averages of losses.\n",
    "    \"\"\"\n",
    "    # Compute the moving average of all individual losses and the total loss.\n",
    "    loss_averages = tf.train.ExponentialMovingAverage(0.9, name='avg')\n",
    "    losses = tf.get_collection('losses')\n",
    "    loss_averages_op = loss_averages.apply(losses + [total_loss])\n",
    "    \n",
    "    # Attach a scalar summmary to all individual losses and the total loss; do the\n",
    "    # same for the averaged version of the losses.\n",
    "    for l in losses + [total_loss]:\n",
    "        # Name each loss as '(raw)' and name the moving average version of the loss\n",
    "        # as the original loss name.\n",
    "        tf.summary.scalar(l.op.name +' (raw)', l)\n",
    "        tf.summary.scalar(l.op.name, loss_averages.average(l))\n",
    "    \n",
    "    return loss_averages_op\n",
    "def train(total_loss, global_step, optimizer, learning_rate, moving_average_decay, update_gradient_vars, log_histograms=True):\n",
    "    # Generate moving averages of all losses and associated summaries.\n",
    "    loss_averages_op = _add_loss_summaries(total_loss)\n",
    "\n",
    "    # Compute gradients.\n",
    "    with tf.control_dependencies([loss_averages_op]):\n",
    "        if optimizer=='ADAGRAD':\n",
    "            opt = tf.train.AdagradOptimizer(learning_rate)\n",
    "        elif optimizer=='ADADELTA':\n",
    "            opt = tf.train.AdadeltaOptimizer(learning_rate, rho=0.9, epsilon=1e-6)\n",
    "        elif optimizer=='ADAM':\n",
    "            opt = tf.train.AdamOptimizer(learning_rate, beta1=0.9, beta2=0.999, epsilon=0.1)\n",
    "        elif optimizer=='RMSPROP':\n",
    "            opt = tf.train.RMSPropOptimizer(learning_rate, decay=0.9, momentum=0.9, epsilon=1.0)\n",
    "        elif optimizer=='MOM':\n",
    "            opt = tf.train.MomentumOptimizer(learning_rate, 0.9, use_nesterov=True)\n",
    "        else:\n",
    "            raise ValueError('Invalid optimization algorithm')\n",
    "    \n",
    "        grads = opt.compute_gradients(total_loss, update_gradient_vars)\n",
    "        \n",
    "    # Apply gradients.\n",
    "    apply_gradient_op = opt.apply_gradients(grads, global_step=global_step)\n",
    "    \n",
    "    # Add histograms for trainable variables.\n",
    "    if log_histograms:\n",
    "        for var in tf.trainable_variables():\n",
    "            tf.summary.histogram(var.op.name, var)\n",
    "    # Add histograms for gradients.\n",
    "    if log_histograms:\n",
    "        for grad, var in grads:\n",
    "            if grad is not None:\n",
    "                tf.summary.histogram(var.op.name + '/gradients', grad)\n",
    "\n",
    "    # Track the moving averages of all trainable variables.\n",
    "    variable_averages = tf.train.ExponentialMovingAverage(\n",
    "        moving_average_decay, global_step)\n",
    "    variables_averages_op = variable_averages.apply(tf.trainable_variables())\n",
    "    \n",
    "    with tf.control_dependencies([apply_gradient_op, variables_averages_op]):\n",
    "        train_op = tf.no_op(name='train')\n",
    "        \n",
    "    return train_op\n",
    "def prewhiten(x):\n",
    "    mean = np.mean(x)\n",
    "    std = np.std(x)\n",
    "    std_adj = np.maximum(std, 1.0/np.sqrt(x.size))\n",
    "    y = np.multiply(np.subtract(x, mean), 1/std_adj)\n",
    "    return y  \n",
    "def crop(image, random_crop, image_size):\n",
    "    if image.shape[1]>image_size:\n",
    "        sz1 = int(image.shape[1]//2)\n",
    "        sz2 = int(image_size//2)\n",
    "        if random_crop:\n",
    "            diff = sz1-sz2\n",
    "            (h, v) = (np.random.randint(-diff, diff+1), np.random.randint(-diff, diff+1))\n",
    "        else:\n",
    "            (h, v) = (0,0)\n",
    "        image = image[(sz1-sz2+v):(sz1+sz2+v),(sz1-sz2+h):(sz1+sz2+h),:]\n",
    "    return image\n",
    "def flip(image, random_flip):\n",
    "    if random_flip and np.random.choice([True, False]):\n",
    "        image = np.fliplr(image)\n",
    "    return image\n",
    "def to_rgb(img):\n",
    "    w, h = img.shape\n",
    "    ret = np.empty((w, h, 3), dtype=np.uint8)\n",
    "    ret[:, :, 0] = ret[:, :, 1] = ret[:, :, 2] = img\n",
    "    return ret\n",
    "def load_data(image_paths, do_random_crop, do_random_flip, image_size, do_prewhiten=True):\n",
    "    nrof_samples = len(image_paths)\n",
    "    images = np.zeros((nrof_samples, image_size, image_size, 3))\n",
    "    for i in range(nrof_samples):\n",
    "        img = misc.imread(image_paths[i])\n",
    "        if img.ndim == 2:\n",
    "            img = to_rgb(img)\n",
    "        if do_prewhiten:\n",
    "            img = prewhiten(img)\n",
    "        img = crop(img, do_random_crop, image_size)\n",
    "        img = flip(img, do_random_flip)\n",
    "        images[i,:,:,:] = img\n",
    "    return images\n",
    "def get_label_batch(label_data, batch_size, batch_index):\n",
    "    nrof_examples = np.size(label_data, 0)\n",
    "    j = batch_index*batch_size % nrof_examples\n",
    "    if j+batch_size<=nrof_examples:\n",
    "        batch = label_data[j:j+batch_size]\n",
    "    else:\n",
    "        x1 = label_data[j:nrof_examples]\n",
    "        x2 = label_data[0:nrof_examples-j]\n",
    "        batch = np.vstack([x1,x2])\n",
    "    batch_int = batch.astype(np.int64)\n",
    "    return batch_int\n",
    "def get_batch(image_data, batch_size, batch_index):\n",
    "    nrof_examples = np.size(image_data, 0)\n",
    "    j = batch_index*batch_size % nrof_examples\n",
    "    if j+batch_size<=nrof_examples:\n",
    "        batch = image_data[j:j+batch_size,:,:,:]\n",
    "    else:\n",
    "        x1 = image_data[j:nrof_examples,:,:,:]\n",
    "        x2 = image_data[0:nrof_examples-j,:,:,:]\n",
    "        batch = np.vstack([x1,x2])\n",
    "    batch_float = batch.astype(np.float32)\n",
    "    return batch_float\n",
    "def get_triplet_batch(triplets, batch_index, batch_size):\n",
    "    ax, px, nx = triplets\n",
    "    a = get_batch(ax, int(batch_size/3), batch_index)\n",
    "    p = get_batch(px, int(batch_size/3), batch_index)\n",
    "    n = get_batch(nx, int(batch_size/3), batch_index)\n",
    "    batch = np.vstack([a, p, n])\n",
    "    return batch\n",
    "def get_learning_rate_from_file(filename, epoch):\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            line = line.split('#', 1)[0]\n",
    "            if line:\n",
    "                par = line.strip().split(':')\n",
    "                e = int(par[0])\n",
    "                if par[1]=='-':\n",
    "                    lr = -1\n",
    "                else:\n",
    "                    lr = float(par[1])\n",
    "                if e <= epoch:\n",
    "                    learning_rate = lr\n",
    "                else:\n",
    "                    return learning_rate\n",
    "class ImageClass():\n",
    "    \"Stores the paths to images for a given class\"\n",
    "    def __init__(self, name, image_paths):\n",
    "        self.name = name\n",
    "        self.image_paths = image_paths\n",
    "    def __str__(self):\n",
    "        return self.name + ', ' + str(len(self.image_paths)) + ' images'\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "def get_dataset(path, has_class_directories=True):\n",
    "    dataset = []\n",
    "    path_exp = os.path.expanduser(path)\n",
    "    classes = [path for path in os.listdir(path_exp) \\\n",
    "                    if os.path.isdir(os.path.join(path_exp, path))]\n",
    "    classes.sort()\n",
    "    nrof_classes = len(classes)\n",
    "    for i in range(nrof_classes):\n",
    "        class_name = classes[i]\n",
    "        facedir = os.path.join(path_exp, class_name)\n",
    "        image_paths = get_image_paths(facedir)\n",
    "        dataset.append(ImageClass(class_name, image_paths))\n",
    "  \n",
    "    return dataset\n",
    "def get_image_paths(facedir):\n",
    "    image_paths = []\n",
    "    if os.path.isdir(facedir):\n",
    "        images = os.listdir(facedir)\n",
    "        image_paths = [os.path.join(facedir,img) for img in images]\n",
    "    return image_paths\n",
    "def split_dataset(dataset, split_ratio, min_nrof_images_per_class, mode):\n",
    "    if mode=='SPLIT_CLASSES':\n",
    "        nrof_classes = len(dataset)\n",
    "        class_indices = np.arange(nrof_classes)\n",
    "        np.random.shuffle(class_indices)\n",
    "        split = int(round(nrof_classes*(1-split_ratio)))\n",
    "        train_set = [dataset[i] for i in class_indices[0:split]]\n",
    "        test_set = [dataset[i] for i in class_indices[split:-1]]\n",
    "    elif mode=='SPLIT_IMAGES':\n",
    "        train_set = []\n",
    "        test_set = []\n",
    "        for cls in dataset:\n",
    "            paths = cls.image_paths\n",
    "            np.random.shuffle(paths)\n",
    "            nrof_images_in_class = len(paths)\n",
    "            split = int(math.floor(nrof_images_in_class*(1-split_ratio)))\n",
    "            if split==nrof_images_in_class:\n",
    "                split = nrof_images_in_class-1\n",
    "            if split>=min_nrof_images_per_class and nrof_images_in_class-split>=1:\n",
    "                train_set.append(ImageClass(cls.name, paths[:split]))\n",
    "                test_set.append(ImageClass(cls.name, paths[split:]))\n",
    "    else:\n",
    "        raise ValueError('Invalid train/test split mode \"%s\"' % mode)\n",
    "    return train_set, test_set\n",
    "def load_model(model, input_map=None):\n",
    "    # Check if the model is a model directory (containing a metagraph and a checkpoint file)\n",
    "    #  or if it is a protobuf file with a frozen graph\n",
    "    \n",
    "    model_exp = os.path.expanduser(model)\n",
    "    if (os.path.isfile(model_exp)):\n",
    "        print('Model filename: %s' % model_exp)\n",
    "        with gfile.FastGFile(model_exp,'rb') as f:\n",
    "            graph_def = tf.GraphDef()\n",
    "            graph_def.ParseFromString(f.read())\n",
    "            tf.import_graph_def(graph_def, input_map=input_map, name='')\n",
    "    else:\n",
    "        print('Model directory: %s' % model_exp)\n",
    "        meta_file, ckpt_file = get_model_filenames(model_exp)\n",
    "        \n",
    "        print('Metagraph file: %s' % meta_file)\n",
    "        print('Checkpoint file: %s' % ckpt_file)\n",
    "      \n",
    "        saver = tf.train.import_meta_graph(os.path.join(model_exp, meta_file), input_map=input_map)\n",
    "        saver.restore(tf.get_default_session(), os.path.join(model_exp, ckpt_file))\n",
    "def get_model_filenames(model_dir):\n",
    "    files = os.listdir(model_dir)\n",
    "    meta_files = [s for s in files if s.endswith('.meta')]\n",
    "    if len(meta_files)==0:\n",
    "        raise ValueError('No meta file found in the model directory (%s)' % model_dir)\n",
    "    elif len(meta_files)>1:\n",
    "        raise ValueError('There should not be more than one meta file in the model directory (%s)' % model_dir)\n",
    "    meta_file = meta_files[0]\n",
    "    ckpt = tf.train.get_checkpoint_state(model_dir)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        ckpt_file = os.path.basename(ckpt.model_checkpoint_path)\n",
    "        return meta_file, ckpt_file\n",
    "\n",
    "    meta_files = [s for s in files if '.ckpt' in s]\n",
    "    max_step = -1\n",
    "    for f in files:\n",
    "        step_str = re.match(r'(^model-[\\w\\- ]+.ckpt-(\\d+))', f)\n",
    "        if step_str is not None and len(step_str.groups())>=2:\n",
    "            step = int(step_str.groups()[1])\n",
    "            if step > max_step:\n",
    "                max_step = step\n",
    "                ckpt_file = step_str.groups()[0]\n",
    "    return meta_file, ckpt_file\n",
    "def distance(embeddings1, embeddings2, distance_metric=0):\n",
    "    if distance_metric==0:\n",
    "        # Euclidian distance\n",
    "        diff = np.subtract(embeddings1, embeddings2)\n",
    "        dist = np.sum(np.square(diff),1)\n",
    "    elif distance_metric==1:\n",
    "        # Distance based on cosine similarity\n",
    "        dot = np.sum(np.multiply(embeddings1, embeddings2), axis=1)\n",
    "        norm = np.linalg.norm(embeddings1, axis=1) * np.linalg.norm(embeddings2, axis=1)\n",
    "        similarity = dot / norm\n",
    "        dist = np.arccos(similarity) / math.pi\n",
    "    else:\n",
    "        raise 'Undefined distance metric %d' % distance_metric \n",
    "        \n",
    "    return dist\n",
    "def calculate_roc(thresholds, embeddings1, embeddings2, actual_issame, nrof_folds=10, distance_metric=0, subtract_mean=False):\n",
    "    assert(embeddings1.shape[0] == embeddings2.shape[0])\n",
    "    assert(embeddings1.shape[1] == embeddings2.shape[1])\n",
    "    nrof_pairs = min(len(actual_issame), embeddings1.shape[0])\n",
    "    nrof_thresholds = len(thresholds)\n",
    "    k_fold = KFold(n_splits=nrof_folds, shuffle=False)\n",
    "    \n",
    "    tprs = np.zeros((nrof_folds,nrof_thresholds))\n",
    "    fprs = np.zeros((nrof_folds,nrof_thresholds))\n",
    "    accuracy = np.zeros((nrof_folds))\n",
    "    \n",
    "    indices = np.arange(nrof_pairs)\n",
    "    \n",
    "    for fold_idx, (train_set, test_set) in enumerate(k_fold.split(indices)):\n",
    "        if subtract_mean:\n",
    "            mean = np.mean(np.concatenate([embeddings1[train_set], embeddings2[train_set]]), axis=0)\n",
    "        else:\n",
    "            mean = 0.0\n",
    "        dist = distance(embeddings1-mean, embeddings2-mean, distance_metric)\n",
    "        \n",
    "        # Find the best threshold for the fold\n",
    "        acc_train = np.zeros((nrof_thresholds))\n",
    "        for threshold_idx, threshold in enumerate(thresholds):\n",
    "            _, _, acc_train[threshold_idx] = calculate_accuracy(threshold, dist[train_set], actual_issame[train_set])\n",
    "        best_threshold_index = np.argmax(acc_train)\n",
    "        for threshold_idx, threshold in enumerate(thresholds):\n",
    "            tprs[fold_idx,threshold_idx], fprs[fold_idx,threshold_idx], _ = calculate_accuracy(threshold, dist[test_set], actual_issame[test_set])\n",
    "        _, _, accuracy[fold_idx] = calculate_accuracy(thresholds[best_threshold_index], dist[test_set], actual_issame[test_set])\n",
    "          \n",
    "        tpr = np.mean(tprs,0)\n",
    "        fpr = np.mean(fprs,0)\n",
    "    return tpr, fpr, accuracy\n",
    "def calculate_accuracy(threshold, dist, actual_issame):\n",
    "    predict_issame = np.less(dist, threshold)\n",
    "    tp = np.sum(np.logical_and(predict_issame, actual_issame))\n",
    "    fp = np.sum(np.logical_and(predict_issame, np.logical_not(actual_issame)))\n",
    "    tn = np.sum(np.logical_and(np.logical_not(predict_issame), np.logical_not(actual_issame)))\n",
    "    fn = np.sum(np.logical_and(np.logical_not(predict_issame), actual_issame))\n",
    "    \n",
    "    tpr = 0 if (tp+fn==0) else float(tp) / float(tp+fn)\n",
    "    fpr = 0 if (fp+tn==0) else float(fp) / float(fp+tn)\n",
    "    acc = float(tp+tn)/dist.size\n",
    "    return tpr, fpr, acc  \n",
    "def calculate_val(thresholds, embeddings1, embeddings2, actual_issame, far_target, nrof_folds=10, distance_metric=0, subtract_mean=False):\n",
    "    assert(embeddings1.shape[0] == embeddings2.shape[0])\n",
    "    assert(embeddings1.shape[1] == embeddings2.shape[1])\n",
    "    nrof_pairs = min(len(actual_issame), embeddings1.shape[0])\n",
    "    nrof_thresholds = len(thresholds)\n",
    "    k_fold = KFold(n_splits=nrof_folds, shuffle=False)\n",
    "    \n",
    "    val = np.zeros(nrof_folds)\n",
    "    far = np.zeros(nrof_folds)\n",
    "    \n",
    "    indices = np.arange(nrof_pairs)\n",
    "    \n",
    "    for fold_idx, (train_set, test_set) in enumerate(k_fold.split(indices)):\n",
    "        if subtract_mean:\n",
    "            mean = np.mean(np.concatenate([embeddings1[train_set], embeddings2[train_set]]), axis=0)\n",
    "        else:\n",
    "            mean = 0.0\n",
    "        dist = distance(embeddings1-mean, embeddings2-mean, distance_metric)\n",
    "        \n",
    "        # Find the threshold that gives FAR = far_target\n",
    "        far_train = np.zeros(nrof_thresholds)\n",
    "        for threshold_idx, threshold in enumerate(thresholds):\n",
    "            _, far_train[threshold_idx] = calculate_val_far(threshold, dist[train_set], actual_issame[train_set])\n",
    "        if np.max(far_train)>=far_target:\n",
    "            f = interpolate.interp1d(far_train, thresholds, kind='slinear')\n",
    "            threshold = f(far_target)\n",
    "        else:\n",
    "            threshold = 0.0\n",
    "    \n",
    "        val[fold_idx], far[fold_idx] = calculate_val_far(threshold, dist[test_set], actual_issame[test_set])\n",
    "        \n",
    "    val_mean = np.mean(val)\n",
    "    far_mean = np.mean(far)\n",
    "    val_std = np.std(val)\n",
    "    return val_mean, val_std, far_mean\n",
    "def calculate_val_far(threshold, dist, actual_issame):\n",
    "    predict_issame = np.less(dist, threshold)\n",
    "    true_accept = np.sum(np.logical_and(predict_issame, actual_issame))\n",
    "    false_accept = np.sum(np.logical_and(predict_issame, np.logical_not(actual_issame)))\n",
    "    n_same = np.sum(actual_issame)\n",
    "    n_diff = np.sum(np.logical_not(actual_issame))\n",
    "    val = float(true_accept) / float(n_same)\n",
    "    far = float(false_accept) / float(n_diff)\n",
    "    return val, far\n",
    "def store_revision_info(src_path, output_dir, arg_string):\n",
    "    try:\n",
    "        # Get git hash\n",
    "        cmd = ['git', 'rev-parse', 'HEAD']\n",
    "        gitproc = Popen(cmd, stdout = PIPE, cwd=src_path)\n",
    "        (stdout, _) = gitproc.communicate()\n",
    "        git_hash = stdout.strip()\n",
    "    except OSError as e:\n",
    "        git_hash = ' '.join(cmd) + ': ' +  e.strerror\n",
    "        \n",
    "    try:\n",
    "        # Get local changes\n",
    "        cmd = ['git', 'diff', 'HEAD']\n",
    "        gitproc = Popen(cmd, stdout = PIPE, cwd=src_path)\n",
    "        (stdout, _) = gitproc.communicate()\n",
    "        git_diff = stdout.strip()\n",
    "    except OSError as e:\n",
    "        git_diff = ' '.join(cmd) + ': ' +  e.strerror\n",
    "    \n",
    "    # Store a text file in the log directory\n",
    "    rev_info_filename = os.path.join(output_dir, 'revision_info.txt')\n",
    "    with open(rev_info_filename, \"w\") as text_file:\n",
    "        text_file.write('arguments: %s\\n--------------------\\n' % arg_string)\n",
    "        text_file.write('tensorflow version: %s\\n--------------------\\n' % tf.__version__)  # @UndefinedVariable\n",
    "        text_file.write('git hash: %s\\n--------------------\\n' % git_hash)\n",
    "        text_file.write('%s' % git_diff)\n",
    "def list_variables(filename):\n",
    "    reader = training.NewCheckpointReader(filename)\n",
    "    variable_map = reader.get_variable_to_shape_map()\n",
    "    names = sorted(variable_map.keys())\n",
    "    return names\n",
    "def put_images_on_grid(images, shape=(16,8)):\n",
    "    nrof_images = images.shape[0]\n",
    "    img_size = images.shape[1]\n",
    "    bw = 3\n",
    "    img = np.zeros((shape[1]*(img_size+bw)+bw, shape[0]*(img_size+bw)+bw, 3), np.float32)\n",
    "    for i in range(shape[1]):\n",
    "        x_start = i*(img_size+bw)+bw\n",
    "        for j in range(shape[0]):\n",
    "            img_index = i*shape[0]+j\n",
    "            if img_index>=nrof_images:\n",
    "                break\n",
    "            y_start = j*(img_size+bw)+bw\n",
    "            img[x_start:x_start+img_size, y_start:y_start+img_size, :] = images[img_index, :, :, :]\n",
    "        if img_index>=nrof_images:\n",
    "            break\n",
    "    return img\n",
    "def write_arguments_to_file(args, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        for key, value in iteritems(vars(args)):\n",
    "            f.write('%s: %s\\n' % (key, str(value)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Align Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Detect Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     9,
     32,
     103,
     138,
     146,
     155,
     186,
     187,
     202,
     203,
     219,
     220,
     243,
     244,
     255,
     264,
     282,
     288,
     385,
     608,
     621,
     647,
     679,
     713,
     722
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from six import string_types, iteritems\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "def layer(op):\n",
    "    \"\"\"Decorator for composable network layers.\"\"\"\n",
    "\n",
    "    def layer_decorated(self, *args, **kwargs):\n",
    "        # Automatically set a name if not provided.\n",
    "        name = kwargs.setdefault('name', self.get_unique_name(op.__name__))\n",
    "        # Figure out the layer inputs.\n",
    "        if len(self.terminals) == 0:\n",
    "            raise RuntimeError('No input variables found for layer %s.' % name)\n",
    "        elif len(self.terminals) == 1:\n",
    "            layer_input = self.terminals[0]\n",
    "        else:\n",
    "            layer_input = list(self.terminals)\n",
    "        # Perform the operation and get the output.\n",
    "        layer_output = op(self, layer_input, *args, **kwargs)\n",
    "        # Add to layer LUT.\n",
    "        self.layers[name] = layer_output\n",
    "        # This output is now the input for the next layer.\n",
    "        self.feed(layer_output)\n",
    "        # Return self for chained calls.\n",
    "        return self\n",
    "\n",
    "    return layer_decorated\n",
    "class Network(object):\n",
    "\n",
    "    def __init__(self, inputs, trainable=True):\n",
    "        # The input nodes for this network\n",
    "        self.inputs = inputs\n",
    "        # The current list of terminal nodes\n",
    "        self.terminals = []\n",
    "        # Mapping from layer names to layers\n",
    "        self.layers = dict(inputs)\n",
    "        # If true, the resulting variables are set as trainable\n",
    "        self.trainable = trainable\n",
    "\n",
    "        self.setup()\n",
    "\n",
    "    def setup(self):\n",
    "        \"\"\"Construct the network. \"\"\"\n",
    "        raise NotImplementedError('Must be implemented by the subclass.')\n",
    "\n",
    "    def load(self, data_path, session, ignore_missing=False):\n",
    "        \"\"\"Load network weights.\n",
    "        data_path: The path to the numpy-serialized network weights\n",
    "        session: The current TensorFlow session\n",
    "        ignore_missing: If true, serialized weights for missing layers are ignored.\n",
    "        \"\"\"\n",
    "        data_dict = np.load(data_path, encoding='latin1', allow_pickle=True).item() #pylint: disable=no-member \n",
    "\n",
    "        for op_name in data_dict:\n",
    "            with tf.variable_scope(op_name, reuse=True):\n",
    "                for param_name, data in iteritems(data_dict[op_name]):\n",
    "                    try:\n",
    "                        var = tf.get_variable(param_name)\n",
    "                        session.run(var.assign(data))\n",
    "                    except ValueError:\n",
    "                        if not ignore_missing:\n",
    "                            raise\n",
    "\n",
    "    def feed(self, *args):\n",
    "        \"\"\"Set the input(s) for the next operation by replacing the terminal nodes.\n",
    "        The arguments can be either layer names or the actual layers.\n",
    "        \"\"\"\n",
    "        assert len(args) != 0\n",
    "        self.terminals = []\n",
    "        for fed_layer in args:\n",
    "            if isinstance(fed_layer, string_types):\n",
    "                try:\n",
    "                    fed_layer = self.layers[fed_layer]\n",
    "                except KeyError:\n",
    "                    raise KeyError('Unknown layer name fed: %s' % fed_layer)\n",
    "            self.terminals.append(fed_layer)\n",
    "        return self\n",
    "\n",
    "    def get_output(self):\n",
    "        \"\"\"Returns the current network output.\"\"\"\n",
    "        return self.terminals[-1]\n",
    "\n",
    "    def get_unique_name(self, prefix):\n",
    "        \"\"\"Returns an index-suffixed unique name for the given prefix.\n",
    "        This is used for auto-generating layer names based on the type-prefix.\n",
    "        \"\"\"\n",
    "        ident = sum(t.startswith(prefix) for t, _ in self.layers.items()) + 1\n",
    "        return '%s_%d' % (prefix, ident)\n",
    "\n",
    "    def make_var(self, name, shape):\n",
    "        \"\"\"Creates a new TensorFlow variable.\"\"\"\n",
    "        return tf.get_variable(name, shape, trainable=self.trainable)\n",
    "\n",
    "    def validate_padding(self, padding):\n",
    "        \"\"\"Verifies that the padding is one of the supported ones.\"\"\"\n",
    "        assert padding in ('SAME', 'VALID')\n",
    "\n",
    "    @layer\n",
    "    def conv(self,\n",
    "             inp,\n",
    "             k_h,\n",
    "             k_w,\n",
    "             c_o,\n",
    "             s_h,\n",
    "             s_w,\n",
    "             name,\n",
    "             relu=True,\n",
    "             padding='SAME',\n",
    "             group=1,\n",
    "             biased=True):\n",
    "        # Verify that the padding is acceptable\n",
    "        self.validate_padding(padding)\n",
    "        # Get the number of channels in the input\n",
    "        c_i = int(inp.get_shape()[-1])\n",
    "        # Verify that the grouping parameter is valid\n",
    "        assert c_i % group == 0\n",
    "        assert c_o % group == 0\n",
    "        # Convolution for a given input and kernel\n",
    "        convolve = lambda i, k: tf.nn.conv2d(i, k, [1, s_h, s_w, 1], padding=padding)\n",
    "        with tf.variable_scope(name) as scope:\n",
    "            kernel = self.make_var('weights', shape=[k_h, k_w, c_i // group, c_o])\n",
    "            # This is the common-case. Convolve the input without any further complications.\n",
    "            output = convolve(inp, kernel)\n",
    "            # Add the biases\n",
    "            if biased:\n",
    "                biases = self.make_var('biases', [c_o])\n",
    "                output = tf.nn.bias_add(output, biases)\n",
    "            if relu:\n",
    "                # ReLU non-linearity\n",
    "                output = tf.nn.relu(output, name=scope.name)\n",
    "            return output\n",
    "\n",
    "    @layer\n",
    "    def prelu(self, inp, name):\n",
    "        with tf.variable_scope(name):\n",
    "            i = int(inp.get_shape()[-1])\n",
    "            alpha = self.make_var('alpha', shape=(i,))\n",
    "            output = tf.nn.relu(inp) + tf.multiply(alpha, -tf.nn.relu(-inp))\n",
    "        return output\n",
    "\n",
    "    @layer\n",
    "    def max_pool(self, inp, k_h, k_w, s_h, s_w, name, padding='SAME'):\n",
    "        self.validate_padding(padding)\n",
    "        return tf.nn.max_pool(inp,\n",
    "                              ksize=[1, k_h, k_w, 1],\n",
    "                              strides=[1, s_h, s_w, 1],\n",
    "                              padding=padding,\n",
    "                              name=name)\n",
    "\n",
    "    @layer\n",
    "    def fc(self, inp, num_out, name, relu=True):\n",
    "        with tf.variable_scope(name):\n",
    "            input_shape = inp.get_shape()\n",
    "            if input_shape.ndims == 4:\n",
    "                # The input is spatial. Vectorize it first.\n",
    "                dim = 1\n",
    "                for d in input_shape[1:].as_list():\n",
    "                    dim *= int(d)\n",
    "                feed_in = tf.reshape(inp, [-1, dim])\n",
    "            else:\n",
    "                feed_in, dim = (inp, input_shape[-1].value)\n",
    "            weights = self.make_var('weights', shape=[dim, num_out])\n",
    "            biases = self.make_var('biases', [num_out])\n",
    "            op = tf.nn.relu_layer if relu else tf.nn.xw_plus_b\n",
    "            fc = op(feed_in, weights, biases, name=name)\n",
    "            return fc\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Multi dimensional softmax,\n",
    "    refer to https://github.com/tensorflow/tensorflow/issues/210\n",
    "    compute softmax along the dimension of target\n",
    "    the native softmax only supports batch_size x dimension\n",
    "    \"\"\"\n",
    "    @layer\n",
    "    def softmax(self, target, axis, name=None):\n",
    "        max_axis = tf.reduce_max(target, axis, keepdims=True)\n",
    "        target_exp = tf.exp(target-max_axis)\n",
    "        normalize = tf.reduce_sum(target_exp, axis, keepdims=True)\n",
    "        softmax = tf.div(target_exp, normalize, name)\n",
    "        return softmax\n",
    "class PNet(Network):\n",
    "    def setup(self):\n",
    "        (self.feed('data') #pylint: disable=no-value-for-parameter, no-member\n",
    "             .conv(3, 3, 10, 1, 1, padding='VALID', relu=False, name='conv1')\n",
    "             .prelu(name='PReLU1')\n",
    "             .max_pool(2, 2, 2, 2, name='pool1')\n",
    "             .conv(3, 3, 16, 1, 1, padding='VALID', relu=False, name='conv2')\n",
    "             .prelu(name='PReLU2')\n",
    "             .conv(3, 3, 32, 1, 1, padding='VALID', relu=False, name='conv3')\n",
    "             .prelu(name='PReLU3')\n",
    "             .conv(1, 1, 2, 1, 1, relu=False, name='conv4-1')\n",
    "             .softmax(3,name='prob1'))\n",
    "\n",
    "        (self.feed('PReLU3') #pylint: disable=no-value-for-parameter\n",
    "             .conv(1, 1, 4, 1, 1, relu=False, name='conv4-2'))\n",
    "class RNet(Network):\n",
    "    def setup(self):\n",
    "        (self.feed('data') #pylint: disable=no-value-for-parameter, no-member\n",
    "             .conv(3, 3, 28, 1, 1, padding='VALID', relu=False, name='conv1')\n",
    "             .prelu(name='prelu1')\n",
    "             .max_pool(3, 3, 2, 2, name='pool1')\n",
    "             .conv(3, 3, 48, 1, 1, padding='VALID', relu=False, name='conv2')\n",
    "             .prelu(name='prelu2')\n",
    "             .max_pool(3, 3, 2, 2, padding='VALID', name='pool2')\n",
    "             .conv(2, 2, 64, 1, 1, padding='VALID', relu=False, name='conv3')\n",
    "             .prelu(name='prelu3')\n",
    "             .fc(128, relu=False, name='conv4')\n",
    "             .prelu(name='prelu4')\n",
    "             .fc(2, relu=False, name='conv5-1')\n",
    "             .softmax(1,name='prob1'))\n",
    "\n",
    "        (self.feed('prelu4') #pylint: disable=no-value-for-parameter\n",
    "             .fc(4, relu=False, name='conv5-2'))\n",
    "class ONet(Network):\n",
    "    def setup(self):\n",
    "        (self.feed('data') #pylint: disable=no-value-for-parameter, no-member\n",
    "             .conv(3, 3, 32, 1, 1, padding='VALID', relu=False, name='conv1')\n",
    "             .prelu(name='prelu1')\n",
    "             .max_pool(3, 3, 2, 2, name='pool1')\n",
    "             .conv(3, 3, 64, 1, 1, padding='VALID', relu=False, name='conv2')\n",
    "             .prelu(name='prelu2')\n",
    "             .max_pool(3, 3, 2, 2, padding='VALID', name='pool2')\n",
    "             .conv(3, 3, 64, 1, 1, padding='VALID', relu=False, name='conv3')\n",
    "             .prelu(name='prelu3')\n",
    "             .max_pool(2, 2, 2, 2, name='pool3')\n",
    "             .conv(2, 2, 128, 1, 1, padding='VALID', relu=False, name='conv4')\n",
    "             .prelu(name='prelu4')\n",
    "             .fc(256, relu=False, name='conv5')\n",
    "             .prelu(name='prelu5')\n",
    "             .fc(2, relu=False, name='conv6-1')\n",
    "             .softmax(1, name='prob1'))\n",
    "\n",
    "        (self.feed('prelu5') #pylint: disable=no-value-for-parameter\n",
    "             .fc(4, relu=False, name='conv6-2'))\n",
    "\n",
    "        (self.feed('prelu5') #pylint: disable=no-value-for-parameter\n",
    "             .fc(10, relu=False, name='conv6-3'))\n",
    "def create_mtcnn(sess, model_path):\n",
    "    if not model_path:\n",
    "        model_path,_ = os.path.split(os.path.realpath(__file__))\n",
    "\n",
    "    with tf.variable_scope('pnet'):\n",
    "        data = tf.placeholder(tf.float32, (None,None,None,3), 'input')\n",
    "        pnet = PNet({'data':data})\n",
    "        pnet.load(os.path.join(model_path, 'det1.npy'), sess)\n",
    "    with tf.variable_scope('rnet'):\n",
    "        data = tf.placeholder(tf.float32, (None,24,24,3), 'input')\n",
    "        rnet = RNet({'data':data})\n",
    "        rnet.load(os.path.join(model_path, 'det2.npy'), sess)\n",
    "    with tf.variable_scope('onet'):\n",
    "        data = tf.placeholder(tf.float32, (None,48,48,3), 'input')\n",
    "        onet = ONet({'data':data})\n",
    "        onet.load(os.path.join(model_path, 'det3.npy'), sess)\n",
    "        \n",
    "    pnet_fun = lambda img : sess.run(('pnet/conv4-2/BiasAdd:0', 'pnet/prob1:0'), feed_dict={'pnet/input:0':img})\n",
    "    rnet_fun = lambda img : sess.run(('rnet/conv5-2/conv5-2:0', 'rnet/prob1:0'), feed_dict={'rnet/input:0':img})\n",
    "    onet_fun = lambda img : sess.run(('onet/conv6-2/conv6-2:0', 'onet/conv6-3/conv6-3:0', 'onet/prob1:0'), feed_dict={'onet/input:0':img})\n",
    "    return pnet_fun, rnet_fun, onet_fun\n",
    "def detect_face(img, minsize, pnet, rnet, onet, threshold, factor):\n",
    "    \"\"\"Detects faces in an image, and returns bounding boxes and points for them.\n",
    "    img: input image\n",
    "    minsize: minimum faces' size\n",
    "    pnet, rnet, onet: caffemodel\n",
    "    threshold: threshold=[th1, th2, th3], th1-3 are three steps's threshold\n",
    "    factor: the factor used to create a scaling pyramid of face sizes to detect in the image.\n",
    "    \"\"\"\n",
    "    factor_count=0\n",
    "    total_boxes=np.empty((0,9))\n",
    "    points=np.empty(0)\n",
    "    h=img.shape[0]\n",
    "    w=img.shape[1]\n",
    "    minl=np.amin([h, w])\n",
    "    m=12.0/minsize\n",
    "    minl=minl*m\n",
    "    # create scale pyramid\n",
    "    scales=[]\n",
    "    while minl>=12:\n",
    "        scales += [m*np.power(factor, factor_count)]\n",
    "        minl = minl*factor\n",
    "        factor_count += 1\n",
    "\n",
    "    # first stage\n",
    "    for scale in scales:\n",
    "        hs=int(np.ceil(h*scale))\n",
    "        ws=int(np.ceil(w*scale))\n",
    "        im_data = imresample(img, (hs, ws))\n",
    "        im_data = (im_data-127.5)*0.0078125\n",
    "        img_x = np.expand_dims(im_data, 0)\n",
    "        img_y = np.transpose(img_x, (0,2,1,3))\n",
    "        out = pnet(img_y)\n",
    "        out0 = np.transpose(out[0], (0,2,1,3))\n",
    "        out1 = np.transpose(out[1], (0,2,1,3))\n",
    "        \n",
    "        boxes, _ = generateBoundingBox(out1[0,:,:,1].copy(), out0[0,:,:,:].copy(), scale, threshold[0])\n",
    "        \n",
    "        # inter-scale nms\n",
    "        pick = nms(boxes.copy(), 0.5, 'Union')\n",
    "        if boxes.size>0 and pick.size>0:\n",
    "            boxes = boxes[pick,:]\n",
    "            total_boxes = np.append(total_boxes, boxes, axis=0)\n",
    "\n",
    "    numbox = total_boxes.shape[0]\n",
    "    if numbox>0:\n",
    "        pick = nms(total_boxes.copy(), 0.7, 'Union')\n",
    "        total_boxes = total_boxes[pick,:]\n",
    "        regw = total_boxes[:,2]-total_boxes[:,0]\n",
    "        regh = total_boxes[:,3]-total_boxes[:,1]\n",
    "        qq1 = total_boxes[:,0]+total_boxes[:,5]*regw\n",
    "        qq2 = total_boxes[:,1]+total_boxes[:,6]*regh\n",
    "        qq3 = total_boxes[:,2]+total_boxes[:,7]*regw\n",
    "        qq4 = total_boxes[:,3]+total_boxes[:,8]*regh\n",
    "        total_boxes = np.transpose(np.vstack([qq1, qq2, qq3, qq4, total_boxes[:,4]]))\n",
    "        total_boxes = rerec(total_boxes.copy())\n",
    "        total_boxes[:,0:4] = np.fix(total_boxes[:,0:4]).astype(np.int32)\n",
    "        dy, edy, dx, edx, y, ey, x, ex, tmpw, tmph = pad(total_boxes.copy(), w, h)\n",
    "\n",
    "    numbox = total_boxes.shape[0]\n",
    "    if numbox>0:\n",
    "        # second stage\n",
    "        tempimg = np.zeros((24,24,3,numbox))\n",
    "        for k in range(0,numbox):\n",
    "            tmp = np.zeros((int(tmph[k]),int(tmpw[k]),3))\n",
    "            tmp[dy[k]-1:edy[k],dx[k]-1:edx[k],:] = img[y[k]-1:ey[k],x[k]-1:ex[k],:]\n",
    "            if tmp.shape[0]>0 and tmp.shape[1]>0 or tmp.shape[0]==0 and tmp.shape[1]==0:\n",
    "                tempimg[:,:,:,k] = imresample(tmp, (24, 24))\n",
    "            else:\n",
    "                return np.empty()\n",
    "        tempimg = (tempimg-127.5)*0.0078125\n",
    "        tempimg1 = np.transpose(tempimg, (3,1,0,2))\n",
    "        out = rnet(tempimg1)\n",
    "        out0 = np.transpose(out[0])\n",
    "        out1 = np.transpose(out[1])\n",
    "        score = out1[1,:]\n",
    "        ipass = np.where(score>threshold[1])\n",
    "        total_boxes = np.hstack([total_boxes[ipass[0],0:4].copy(), np.expand_dims(score[ipass].copy(),1)])\n",
    "        mv = out0[:,ipass[0]]\n",
    "        if total_boxes.shape[0]>0:\n",
    "            pick = nms(total_boxes, 0.7, 'Union')\n",
    "            total_boxes = total_boxes[pick,:]\n",
    "            total_boxes = bbreg(total_boxes.copy(), np.transpose(mv[:,pick]))\n",
    "            total_boxes = rerec(total_boxes.copy())\n",
    "\n",
    "    numbox = total_boxes.shape[0]\n",
    "    if numbox>0:\n",
    "        # third stage\n",
    "        total_boxes = np.fix(total_boxes).astype(np.int32)\n",
    "        dy, edy, dx, edx, y, ey, x, ex, tmpw, tmph = pad(total_boxes.copy(), w, h)\n",
    "        tempimg = np.zeros((48,48,3,numbox))\n",
    "        for k in range(0,numbox):\n",
    "            tmp = np.zeros((int(tmph[k]),int(tmpw[k]),3))\n",
    "            tmp[dy[k]-1:edy[k],dx[k]-1:edx[k],:] = img[y[k]-1:ey[k],x[k]-1:ex[k],:]\n",
    "            if tmp.shape[0]>0 and tmp.shape[1]>0 or tmp.shape[0]==0 and tmp.shape[1]==0:\n",
    "                tempimg[:,:,:,k] = imresample(tmp, (48, 48))\n",
    "            else:\n",
    "                return np.empty()\n",
    "        tempimg = (tempimg-127.5)*0.0078125\n",
    "        tempimg1 = np.transpose(tempimg, (3,1,0,2))\n",
    "        out = onet(tempimg1)\n",
    "        out0 = np.transpose(out[0])\n",
    "        out1 = np.transpose(out[1])\n",
    "        out2 = np.transpose(out[2])\n",
    "        score = out2[1,:]\n",
    "        points = out1\n",
    "        ipass = np.where(score>threshold[2])\n",
    "        points = points[:,ipass[0]]\n",
    "        total_boxes = np.hstack([total_boxes[ipass[0],0:4].copy(), np.expand_dims(score[ipass].copy(),1)])\n",
    "        mv = out0[:,ipass[0]]\n",
    "\n",
    "        w = total_boxes[:,2]-total_boxes[:,0]+1\n",
    "        h = total_boxes[:,3]-total_boxes[:,1]+1\n",
    "        points[0:5,:] = np.tile(w,(5, 1))*points[0:5,:] + np.tile(total_boxes[:,0],(5, 1))-1\n",
    "        points[5:10,:] = np.tile(h,(5, 1))*points[5:10,:] + np.tile(total_boxes[:,1],(5, 1))-1\n",
    "        if total_boxes.shape[0]>0:\n",
    "            total_boxes = bbreg(total_boxes.copy(), np.transpose(mv))\n",
    "            pick = nms(total_boxes.copy(), 0.7, 'Min')\n",
    "            total_boxes = total_boxes[pick,:]\n",
    "            points = points[:,pick]\n",
    "                \n",
    "    return total_boxes, points\n",
    "def bulk_detect_face(images, detection_window_size_ratio, pnet, rnet, onet, threshold, factor):\n",
    "    \"\"\"Detects faces in a list of images\n",
    "    images: list containing input images\n",
    "    detection_window_size_ratio: ratio of minimum face size to smallest image dimension\n",
    "    pnet, rnet, onet: caffemodel\n",
    "    threshold: threshold=[th1 th2 th3], th1-3 are three steps's threshold [0-1]\n",
    "    factor: the factor used to create a scaling pyramid of face sizes to detect in the image.\n",
    "    \"\"\"\n",
    "    all_scales = [None] * len(images)\n",
    "    images_with_boxes = [None] * len(images)\n",
    "\n",
    "    for i in range(len(images)):\n",
    "        images_with_boxes[i] = {'total_boxes': np.empty((0, 9))}\n",
    "\n",
    "    # create scale pyramid\n",
    "    for index, img in enumerate(images):\n",
    "        all_scales[index] = []\n",
    "        h = img.shape[0]\n",
    "        w = img.shape[1]\n",
    "        minsize = int(detection_window_size_ratio * np.minimum(w, h))\n",
    "        factor_count = 0\n",
    "        minl = np.amin([h, w])\n",
    "        if minsize <= 12:\n",
    "            minsize = 12\n",
    "\n",
    "        m = 12.0 / minsize\n",
    "        minl = minl * m\n",
    "        while minl >= 12:\n",
    "            all_scales[index].append(m * np.power(factor, factor_count))\n",
    "            minl = minl * factor\n",
    "            factor_count += 1\n",
    "\n",
    "    # # # # # # # # # # # # #\n",
    "    # first stage - fast proposal network (pnet) to obtain face candidates\n",
    "    # # # # # # # # # # # # #\n",
    "\n",
    "    images_obj_per_resolution = {}\n",
    "\n",
    "    # TODO: use some type of rounding to number module 8 to increase probability that pyramid images will have the same resolution across input images\n",
    "\n",
    "    for index, scales in enumerate(all_scales):\n",
    "        h = images[index].shape[0]\n",
    "        w = images[index].shape[1]\n",
    "\n",
    "        for scale in scales:\n",
    "            hs = int(np.ceil(h * scale))\n",
    "            ws = int(np.ceil(w * scale))\n",
    "\n",
    "            if (ws, hs) not in images_obj_per_resolution:\n",
    "                images_obj_per_resolution[(ws, hs)] = []\n",
    "\n",
    "            im_data = imresample(images[index], (hs, ws))\n",
    "            im_data = (im_data - 127.5) * 0.0078125\n",
    "            img_y = np.transpose(im_data, (1, 0, 2))  # caffe uses different dimensions ordering\n",
    "            images_obj_per_resolution[(ws, hs)].append({'scale': scale, 'image': img_y, 'index': index})\n",
    "\n",
    "    for resolution in images_obj_per_resolution:\n",
    "        images_per_resolution = [i['image'] for i in images_obj_per_resolution[resolution]]\n",
    "        outs = pnet(images_per_resolution)\n",
    "\n",
    "        for index in range(len(outs[0])):\n",
    "            scale = images_obj_per_resolution[resolution][index]['scale']\n",
    "            image_index = images_obj_per_resolution[resolution][index]['index']\n",
    "            out0 = np.transpose(outs[0][index], (1, 0, 2))\n",
    "            out1 = np.transpose(outs[1][index], (1, 0, 2))\n",
    "\n",
    "            boxes, _ = generateBoundingBox(out1[:, :, 1].copy(), out0[:, :, :].copy(), scale, threshold[0])\n",
    "\n",
    "            # inter-scale nms\n",
    "            pick = nms(boxes.copy(), 0.5, 'Union')\n",
    "            if boxes.size > 0 and pick.size > 0:\n",
    "                boxes = boxes[pick, :]\n",
    "                images_with_boxes[image_index]['total_boxes'] = np.append(images_with_boxes[image_index]['total_boxes'],\n",
    "                                                                          boxes,\n",
    "                                                                          axis=0)\n",
    "\n",
    "    for index, image_obj in enumerate(images_with_boxes):\n",
    "        numbox = image_obj['total_boxes'].shape[0]\n",
    "        if numbox > 0:\n",
    "            h = images[index].shape[0]\n",
    "            w = images[index].shape[1]\n",
    "            pick = nms(image_obj['total_boxes'].copy(), 0.7, 'Union')\n",
    "            image_obj['total_boxes'] = image_obj['total_boxes'][pick, :]\n",
    "            regw = image_obj['total_boxes'][:, 2] - image_obj['total_boxes'][:, 0]\n",
    "            regh = image_obj['total_boxes'][:, 3] - image_obj['total_boxes'][:, 1]\n",
    "            qq1 = image_obj['total_boxes'][:, 0] + image_obj['total_boxes'][:, 5] * regw\n",
    "            qq2 = image_obj['total_boxes'][:, 1] + image_obj['total_boxes'][:, 6] * regh\n",
    "            qq3 = image_obj['total_boxes'][:, 2] + image_obj['total_boxes'][:, 7] * regw\n",
    "            qq4 = image_obj['total_boxes'][:, 3] + image_obj['total_boxes'][:, 8] * regh\n",
    "            image_obj['total_boxes'] = np.transpose(np.vstack([qq1, qq2, qq3, qq4, image_obj['total_boxes'][:, 4]]))\n",
    "            image_obj['total_boxes'] = rerec(image_obj['total_boxes'].copy())\n",
    "            image_obj['total_boxes'][:, 0:4] = np.fix(image_obj['total_boxes'][:, 0:4]).astype(np.int32)\n",
    "            dy, edy, dx, edx, y, ey, x, ex, tmpw, tmph = pad(image_obj['total_boxes'].copy(), w, h)\n",
    "\n",
    "            numbox = image_obj['total_boxes'].shape[0]\n",
    "            tempimg = np.zeros((24, 24, 3, numbox))\n",
    "\n",
    "            if numbox > 0:\n",
    "                for k in range(0, numbox):\n",
    "                    tmp = np.zeros((int(tmph[k]), int(tmpw[k]), 3))\n",
    "                    tmp[dy[k] - 1:edy[k], dx[k] - 1:edx[k], :] = images[index][y[k] - 1:ey[k], x[k] - 1:ex[k], :]\n",
    "                    if tmp.shape[0] > 0 and tmp.shape[1] > 0 or tmp.shape[0] == 0 and tmp.shape[1] == 0:\n",
    "                        tempimg[:, :, :, k] = imresample(tmp, (24, 24))\n",
    "                    else:\n",
    "                        return np.empty()\n",
    "\n",
    "                tempimg = (tempimg - 127.5) * 0.0078125\n",
    "                image_obj['rnet_input'] = np.transpose(tempimg, (3, 1, 0, 2))\n",
    "\n",
    "    # # # # # # # # # # # # #\n",
    "    # second stage - refinement of face candidates with rnet\n",
    "    # # # # # # # # # # # # #\n",
    "\n",
    "    bulk_rnet_input = np.empty((0, 24, 24, 3))\n",
    "    for index, image_obj in enumerate(images_with_boxes):\n",
    "        if 'rnet_input' in image_obj:\n",
    "            bulk_rnet_input = np.append(bulk_rnet_input, image_obj['rnet_input'], axis=0)\n",
    "\n",
    "    out = rnet(bulk_rnet_input)\n",
    "    out0 = np.transpose(out[0])\n",
    "    out1 = np.transpose(out[1])\n",
    "    score = out1[1, :]\n",
    "\n",
    "    i = 0\n",
    "    for index, image_obj in enumerate(images_with_boxes):\n",
    "        if 'rnet_input' not in image_obj:\n",
    "            continue\n",
    "\n",
    "        rnet_input_count = image_obj['rnet_input'].shape[0]\n",
    "        score_per_image = score[i:i + rnet_input_count]\n",
    "        out0_per_image = out0[:, i:i + rnet_input_count]\n",
    "\n",
    "        ipass = np.where(score_per_image > threshold[1])\n",
    "        image_obj['total_boxes'] = np.hstack([image_obj['total_boxes'][ipass[0], 0:4].copy(),\n",
    "                                              np.expand_dims(score_per_image[ipass].copy(), 1)])\n",
    "\n",
    "        mv = out0_per_image[:, ipass[0]]\n",
    "\n",
    "        if image_obj['total_boxes'].shape[0] > 0:\n",
    "            h = images[index].shape[0]\n",
    "            w = images[index].shape[1]\n",
    "            pick = nms(image_obj['total_boxes'], 0.7, 'Union')\n",
    "            image_obj['total_boxes'] = image_obj['total_boxes'][pick, :]\n",
    "            image_obj['total_boxes'] = bbreg(image_obj['total_boxes'].copy(), np.transpose(mv[:, pick]))\n",
    "            image_obj['total_boxes'] = rerec(image_obj['total_boxes'].copy())\n",
    "\n",
    "            numbox = image_obj['total_boxes'].shape[0]\n",
    "\n",
    "            if numbox > 0:\n",
    "                tempimg = np.zeros((48, 48, 3, numbox))\n",
    "                image_obj['total_boxes'] = np.fix(image_obj['total_boxes']).astype(np.int32)\n",
    "                dy, edy, dx, edx, y, ey, x, ex, tmpw, tmph = pad(image_obj['total_boxes'].copy(), w, h)\n",
    "\n",
    "                for k in range(0, numbox):\n",
    "                    tmp = np.zeros((int(tmph[k]), int(tmpw[k]), 3))\n",
    "                    tmp[dy[k] - 1:edy[k], dx[k] - 1:edx[k], :] = images[index][y[k] - 1:ey[k], x[k] - 1:ex[k], :]\n",
    "                    if tmp.shape[0] > 0 and tmp.shape[1] > 0 or tmp.shape[0] == 0 and tmp.shape[1] == 0:\n",
    "                        tempimg[:, :, :, k] = imresample(tmp, (48, 48))\n",
    "                    else:\n",
    "                        return np.empty()\n",
    "                tempimg = (tempimg - 127.5) * 0.0078125\n",
    "                image_obj['onet_input'] = np.transpose(tempimg, (3, 1, 0, 2))\n",
    "\n",
    "        i += rnet_input_count\n",
    "\n",
    "    # # # # # # # # # # # # #\n",
    "    # third stage - further refinement and facial landmarks positions with onet\n",
    "    # # # # # # # # # # # # #\n",
    "\n",
    "    bulk_onet_input = np.empty((0, 48, 48, 3))\n",
    "    for index, image_obj in enumerate(images_with_boxes):\n",
    "        if 'onet_input' in image_obj:\n",
    "            bulk_onet_input = np.append(bulk_onet_input, image_obj['onet_input'], axis=0)\n",
    "\n",
    "    out = onet(bulk_onet_input)\n",
    "\n",
    "    out0 = np.transpose(out[0])\n",
    "    out1 = np.transpose(out[1])\n",
    "    out2 = np.transpose(out[2])\n",
    "    score = out2[1, :]\n",
    "    points = out1\n",
    "\n",
    "    i = 0\n",
    "    ret = []\n",
    "    for index, image_obj in enumerate(images_with_boxes):\n",
    "        if 'onet_input' not in image_obj:\n",
    "            ret.append(None)\n",
    "            continue\n",
    "\n",
    "        onet_input_count = image_obj['onet_input'].shape[0]\n",
    "\n",
    "        out0_per_image = out0[:, i:i + onet_input_count]\n",
    "        score_per_image = score[i:i + onet_input_count]\n",
    "        points_per_image = points[:, i:i + onet_input_count]\n",
    "\n",
    "        ipass = np.where(score_per_image > threshold[2])\n",
    "        points_per_image = points_per_image[:, ipass[0]]\n",
    "\n",
    "        image_obj['total_boxes'] = np.hstack([image_obj['total_boxes'][ipass[0], 0:4].copy(),\n",
    "                                              np.expand_dims(score_per_image[ipass].copy(), 1)])\n",
    "        mv = out0_per_image[:, ipass[0]]\n",
    "\n",
    "        w = image_obj['total_boxes'][:, 2] - image_obj['total_boxes'][:, 0] + 1\n",
    "        h = image_obj['total_boxes'][:, 3] - image_obj['total_boxes'][:, 1] + 1\n",
    "        points_per_image[0:5, :] = np.tile(w, (5, 1)) * points_per_image[0:5, :] + np.tile(\n",
    "            image_obj['total_boxes'][:, 0], (5, 1)) - 1\n",
    "        points_per_image[5:10, :] = np.tile(h, (5, 1)) * points_per_image[5:10, :] + np.tile(\n",
    "            image_obj['total_boxes'][:, 1], (5, 1)) - 1\n",
    "\n",
    "        if image_obj['total_boxes'].shape[0] > 0:\n",
    "            image_obj['total_boxes'] = bbreg(image_obj['total_boxes'].copy(), np.transpose(mv))\n",
    "            pick = nms(image_obj['total_boxes'].copy(), 0.7, 'Min')\n",
    "            image_obj['total_boxes'] = image_obj['total_boxes'][pick, :]\n",
    "            points_per_image = points_per_image[:, pick]\n",
    "\n",
    "            ret.append((image_obj['total_boxes'], points_per_image))\n",
    "        else:\n",
    "            ret.append(None)\n",
    "\n",
    "        i += onet_input_count\n",
    "\n",
    "    return ret\n",
    "# function [boundingbox] = bbreg(boundingbox,reg)\n",
    "def bbreg(boundingbox,reg):\n",
    "    \"\"\"Calibrate bounding boxes\"\"\"\n",
    "    if reg.shape[1]==1:\n",
    "        reg = np.reshape(reg, (reg.shape[2], reg.shape[3]))\n",
    "\n",
    "    w = boundingbox[:,2]-boundingbox[:,0]+1\n",
    "    h = boundingbox[:,3]-boundingbox[:,1]+1\n",
    "    b1 = boundingbox[:,0]+reg[:,0]*w\n",
    "    b2 = boundingbox[:,1]+reg[:,1]*h\n",
    "    b3 = boundingbox[:,2]+reg[:,2]*w\n",
    "    b4 = boundingbox[:,3]+reg[:,3]*h\n",
    "    boundingbox[:,0:4] = np.transpose(np.vstack([b1, b2, b3, b4 ]))\n",
    "    return boundingbox\n",
    "def generateBoundingBox(imap, reg, scale, t):\n",
    "    \"\"\"Use heatmap to generate bounding boxes\"\"\"\n",
    "    stride=2\n",
    "    cellsize=12\n",
    "\n",
    "    imap = np.transpose(imap)\n",
    "    dx1 = np.transpose(reg[:,:,0])\n",
    "    dy1 = np.transpose(reg[:,:,1])\n",
    "    dx2 = np.transpose(reg[:,:,2])\n",
    "    dy2 = np.transpose(reg[:,:,3])\n",
    "    y, x = np.where(imap >= t)\n",
    "    if y.shape[0]==1:\n",
    "        dx1 = np.flipud(dx1)\n",
    "        dy1 = np.flipud(dy1)\n",
    "        dx2 = np.flipud(dx2)\n",
    "        dy2 = np.flipud(dy2)\n",
    "    score = imap[(y,x)]\n",
    "    reg = np.transpose(np.vstack([ dx1[(y,x)], dy1[(y,x)], dx2[(y,x)], dy2[(y,x)] ]))\n",
    "    if reg.size==0:\n",
    "        reg = np.empty((0,3))\n",
    "    bb = np.transpose(np.vstack([y,x]))\n",
    "    q1 = np.fix((stride*bb+1)/scale)\n",
    "    q2 = np.fix((stride*bb+cellsize-1+1)/scale)\n",
    "    boundingbox = np.hstack([q1, q2, np.expand_dims(score,1), reg])\n",
    "    return boundingbox, reg\n",
    "# function pick = nms(boxes,threshold,type)\n",
    "def nms(boxes, threshold, method):\n",
    "    if boxes.size==0:\n",
    "        return np.empty((0,3))\n",
    "    x1 = boxes[:,0]\n",
    "    y1 = boxes[:,1]\n",
    "    x2 = boxes[:,2]\n",
    "    y2 = boxes[:,3]\n",
    "    s = boxes[:,4]\n",
    "    area = (x2-x1+1) * (y2-y1+1)\n",
    "    I = np.argsort(s)\n",
    "    pick = np.zeros_like(s, dtype=np.int16)\n",
    "    counter = 0\n",
    "    while I.size>0:\n",
    "        i = I[-1]\n",
    "        pick[counter] = i\n",
    "        counter += 1\n",
    "        idx = I[0:-1]\n",
    "        xx1 = np.maximum(x1[i], x1[idx])\n",
    "        yy1 = np.maximum(y1[i], y1[idx])\n",
    "        xx2 = np.minimum(x2[i], x2[idx])\n",
    "        yy2 = np.minimum(y2[i], y2[idx])\n",
    "        w = np.maximum(0.0, xx2-xx1+1)\n",
    "        h = np.maximum(0.0, yy2-yy1+1)\n",
    "        inter = w * h\n",
    "        if method is 'Min':\n",
    "            o = inter / np.minimum(area[i], area[idx])\n",
    "        else:\n",
    "            o = inter / (area[i] + area[idx] - inter)\n",
    "        I = I[np.where(o<=threshold)]\n",
    "    pick = pick[0:counter]\n",
    "    return pick\n",
    "# function [dy edy dx edx y ey x ex tmpw tmph] = pad(total_boxes,w,h)\n",
    "def pad(total_boxes, w, h):\n",
    "    \"\"\"Compute the padding coordinates (pad the bounding boxes to square)\"\"\"\n",
    "    tmpw = (total_boxes[:,2]-total_boxes[:,0]+1).astype(np.int32)\n",
    "    tmph = (total_boxes[:,3]-total_boxes[:,1]+1).astype(np.int32)\n",
    "    numbox = total_boxes.shape[0]\n",
    "\n",
    "    dx = np.ones((numbox), dtype=np.int32)\n",
    "    dy = np.ones((numbox), dtype=np.int32)\n",
    "    edx = tmpw.copy().astype(np.int32)\n",
    "    edy = tmph.copy().astype(np.int32)\n",
    "\n",
    "    x = total_boxes[:,0].copy().astype(np.int32)\n",
    "    y = total_boxes[:,1].copy().astype(np.int32)\n",
    "    ex = total_boxes[:,2].copy().astype(np.int32)\n",
    "    ey = total_boxes[:,3].copy().astype(np.int32)\n",
    "\n",
    "    tmp = np.where(ex>w)\n",
    "    edx.flat[tmp] = np.expand_dims(-ex[tmp]+w+tmpw[tmp],1)\n",
    "    ex[tmp] = w\n",
    "    \n",
    "    tmp = np.where(ey>h)\n",
    "    edy.flat[tmp] = np.expand_dims(-ey[tmp]+h+tmph[tmp],1)\n",
    "    ey[tmp] = h\n",
    "\n",
    "    tmp = np.where(x<1)\n",
    "    dx.flat[tmp] = np.expand_dims(2-x[tmp],1)\n",
    "    x[tmp] = 1\n",
    "\n",
    "    tmp = np.where(y<1)\n",
    "    dy.flat[tmp] = np.expand_dims(2-y[tmp],1)\n",
    "    y[tmp] = 1\n",
    "    \n",
    "    return dy, edy, dx, edx, y, ey, x, ex, tmpw, tmph\n",
    "# function [bboxA] = rerec(bboxA)\n",
    "def rerec(bboxA):\n",
    "    \"\"\"Convert bboxA to square.\"\"\"\n",
    "    h = bboxA[:,3]-bboxA[:,1]\n",
    "    w = bboxA[:,2]-bboxA[:,0]\n",
    "    l = np.maximum(w, h)\n",
    "    bboxA[:,0] = bboxA[:,0]+w*0.5-l*0.5\n",
    "    bboxA[:,1] = bboxA[:,1]+h*0.5-l*0.5\n",
    "    bboxA[:,2:4] = bboxA[:,0:2] + np.transpose(np.tile(l,(2,1)))\n",
    "    return bboxA\n",
    "def imresample(img, sz):\n",
    "    im_data = cv2.resize(img, (sz[1], sz[0]), interpolation=cv2.INTER_AREA) #@UndefinedVariable\n",
    "    return im_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     10,
     22,
     36
    ],
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CfgNode({'input_dir': 'Datasets/lfw/raw/', 'output_dir': 'Datasets/lfw/lfw_mtcnnpy_160', 'image_size': 160, 'margin': 32, 'random_order': True, 'gpu_memory_fraction': 1.0, 'detect_multiple_faces': False})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "align_cfg = CN()\n",
    "align_cfg.input_dir= 'Datasets/lfw/raw/'\n",
    "align_cfg.output_dir = 'Datasets/lfw/lfw_mtcnnpy_160'\n",
    "align_cfg.image_size = 160\n",
    "align_cfg.margin = 32\n",
    "align_cfg.random_order = True\n",
    "align_cfg.gpu_memory_fraction = 1.0\n",
    "align_cfg.detect_multiple_faces = False\n",
    "align_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0,
     3
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def align_main(args):\n",
    "    sleep(random.random())\n",
    "    output_dir = os.path.expanduser(args.output_dir)\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    #Store some git revision info in a text file in the log directory\n",
    "    src_path,_ = os.path.split(os.getcwd())\n",
    "    store_revision_info(src_path, output_dir, ' '.join(sys.argv))\n",
    "    dataset = get_dataset(args.input_dir)\n",
    "    \n",
    "    print('Creating networks and loading parameters')\n",
    "    \n",
    "    with tf.Graph().as_default():\n",
    "        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=args.gpu_memory_fraction)\n",
    "        sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=False))\n",
    "        with sess.as_default():\n",
    "            pnet, rnet, onet = create_mtcnn(sess, '/home/unreal/rahul/New/Face/facenet/src/align/')\n",
    "    \n",
    "    minsize = 20 # minimum size of face\n",
    "    threshold = [ 0.6, 0.7, 0.7 ]  # three steps's threshold\n",
    "    factor = 0.709 # scale factor\n",
    "\n",
    "    # Add a random key to the filename to allow alignment using multiple processes\n",
    "    random_key = np.random.randint(0, high=99999)\n",
    "    bounding_boxes_filename = os.path.join(output_dir, 'bounding_boxes_%05d.txt' % random_key)\n",
    "    \n",
    "    with open(bounding_boxes_filename, \"w\") as text_file:\n",
    "        nrof_images_total = 0\n",
    "        nrof_successfully_aligned = 0\n",
    "        if args.random_order:\n",
    "            random.shuffle(dataset)\n",
    "        for cls in dataset:\n",
    "            output_class_dir = os.path.join(output_dir, cls.name)\n",
    "            if not os.path.exists(output_class_dir):\n",
    "                os.makedirs(output_class_dir)\n",
    "                if args.random_order:\n",
    "                    random.shuffle(cls.image_paths)\n",
    "            for image_path in cls.image_paths:\n",
    "                nrof_images_total += 1\n",
    "                filename = os.path.splitext(os.path.split(image_path)[1])[0]\n",
    "                output_filename = os.path.join(output_class_dir, filename+'.png')\n",
    "                print(image_path)\n",
    "                if not os.path.exists(output_filename):\n",
    "                    try:\n",
    "                        img = misc.imread(image_path)\n",
    "                    except (IOError, ValueError, IndexError) as e:\n",
    "                        errorMessage = '{}: {}'.format(image_path, e)\n",
    "                        print(errorMessage)\n",
    "                    else:\n",
    "                        if img.ndim<2:\n",
    "                            print('Unable to align \"%s\"' % image_path)\n",
    "                            text_file.write('%s\\n' % (output_filename))\n",
    "                            continue\n",
    "                        if img.ndim == 2:\n",
    "                            img = to_rgb(img)\n",
    "                        img = img[:,:,0:3]\n",
    "    \n",
    "                        bounding_boxes, _ = detect_face(img, minsize, pnet, rnet, onet, threshold, factor)\n",
    "                        nrof_faces = bounding_boxes.shape[0]\n",
    "                        if nrof_faces>0:\n",
    "                            det = bounding_boxes[:,0:4]\n",
    "                            det_arr = []\n",
    "                            img_size = np.asarray(img.shape)[0:2]\n",
    "                            if nrof_faces>1:\n",
    "                                if args.detect_multiple_faces:\n",
    "                                    for i in range(nrof_faces):\n",
    "                                        det_arr.append(np.squeeze(det[i]))\n",
    "                                else:\n",
    "                                    bounding_box_size = (det[:,2]-det[:,0])*(det[:,3]-det[:,1])\n",
    "                                    img_center = img_size / 2\n",
    "                                    offsets = np.vstack([ (det[:,0]+det[:,2])/2-img_center[1], (det[:,1]+det[:,3])/2-img_center[0] ])\n",
    "                                    offset_dist_squared = np.sum(np.power(offsets,2.0),0)\n",
    "                                    index = np.argmax(bounding_box_size-offset_dist_squared*2.0) # some extra weight on the centering\n",
    "                                    det_arr.append(det[index,:])\n",
    "                            else:\n",
    "                                det_arr.append(np.squeeze(det))\n",
    "\n",
    "                            for i, det in enumerate(det_arr):\n",
    "                                det = np.squeeze(det)\n",
    "                                bb = np.zeros(4, dtype=np.int32)\n",
    "                                bb[0] = np.maximum(det[0]-args.margin/2, 0)\n",
    "                                bb[1] = np.maximum(det[1]-args.margin/2, 0)\n",
    "                                bb[2] = np.minimum(det[2]+args.margin/2, img_size[1])\n",
    "                                bb[3] = np.minimum(det[3]+args.margin/2, img_size[0])\n",
    "                                cropped = img[bb[1]:bb[3],bb[0]:bb[2],:]\n",
    "                                scaled = misc.imresize(cropped, (args.image_size, args.image_size), interp='bilinear')\n",
    "                                nrof_successfully_aligned += 1\n",
    "                                filename_base, file_extension = os.path.splitext(output_filename)\n",
    "                                if args.detect_multiple_faces:\n",
    "                                    output_filename_n = \"{}_{}{}\".format(filename_base, i, file_extension)\n",
    "                                else:\n",
    "                                    output_filename_n = \"{}{}\".format(filename_base, file_extension)\n",
    "                                misc.imsave(output_filename_n, scaled)\n",
    "                                text_file.write('%s %d %d %d %d\\n' % (output_filename_n, bb[0], bb[1], bb[2], bb[3]))\n",
    "                        else:\n",
    "                            print('Unable to align \"%s\"' % image_path)\n",
    "                            text_file.write('%s\\n' % (output_filename))\n",
    "                            \n",
    "    print('Total number of images: %d' % nrof_images_total)\n",
    "    print('Number of successfully aligned images: %d' % nrof_successfully_aligned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# python src/align/align_dataset_mtcnn.py  ~/datasets/lfw/raw ~/datasets/lfw/lfw_mtcnnpy_160 --image_size 160  --margin 32  --random_order  --gpu_memory_fraction 0.25 \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# align_main(align_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir Pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd Pretrained/\n",
    "# !gdown https://drive.google.com/uc?id=10jjuS036Kp5U9HXo76AnChHWeu19vMgE\n",
    "# %cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python src/validate_on_lfw.py ~/datasets/lfw/lfw_mtcnnpy_160  ~/models/facenet/20180402-114759  --distance_metric 1  --use_flipped_images  --subtract_mean \\\n",
    "# --use_fixed_image_standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LFW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "code_folding": [
     7,
     19,
     43,
     51
    ]
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def lfw_evaluate(embeddings, actual_issame, nrof_folds=10, distance_metric=0, subtract_mean=False):\n",
    "    # Calculate evaluation metrics\n",
    "    thresholds = np.arange(0, 4, 0.01)\n",
    "    embeddings1 = embeddings[0::2]\n",
    "    embeddings2 = embeddings[1::2]\n",
    "    tpr, fpr, accuracy = calculate_roc(thresholds, embeddings1, embeddings2,\n",
    "        np.asarray(actual_issame), nrof_folds=nrof_folds, distance_metric=distance_metric, subtract_mean=subtract_mean)\n",
    "    thresholds = np.arange(0, 4, 0.001)\n",
    "    val, val_std, far = calculate_val(thresholds, embeddings1, embeddings2,\n",
    "        np.asarray(actual_issame), 1e-3, nrof_folds=nrof_folds, distance_metric=distance_metric, subtract_mean=subtract_mean)\n",
    "    return tpr, fpr, accuracy, val, val_std, far\n",
    "\n",
    "def get_paths(lfw_dir, pairs):\n",
    "    lfw_dir = valid_args.lfw_dir\n",
    "    nrof_skipped_pairs = 0\n",
    "    path_list = []\n",
    "    issame_list = []\n",
    "    for pair in pairs:\n",
    "        if len(pair) == 3:\n",
    "            path0 = add_extension(os.path.join(lfw_dir, pair[0], pair[0] + '_' + '%04d' % int(pair[1])))\n",
    "            path1 = add_extension(os.path.join(lfw_dir, pair[0], pair[0] + '_' + '%04d' % int(pair[2])))\n",
    "            issame = True\n",
    "        elif len(pair) == 4:\n",
    "            path0 = add_extension(os.path.join(lfw_dir, pair[0], pair[0] + '_' + '%04d' % int(pair[1])))\n",
    "            path1 = add_extension(os.path.join(lfw_dir, pair[2], pair[2] + '_' + '%04d' % int(pair[3])))\n",
    "            issame = False\n",
    "        if os.path.exists(path0) and os.path.exists(path1):    # Only add the pair if both paths exist\n",
    "            path_list += (path0,path1)\n",
    "            issame_list.append(issame)\n",
    "        else:\n",
    "            nrof_skipped_pairs += 1\n",
    "    if nrof_skipped_pairs>0:\n",
    "        print('Skipped %d image pairs' % nrof_skipped_pairs)\n",
    "    \n",
    "    return path_list, issame_list\n",
    "  \n",
    "def add_extension(path):\n",
    "    if os.path.exists(path+'.jpg'):\n",
    "        return path+'.jpg'\n",
    "    elif os.path.exists(path+'.png'):\n",
    "        return path+'.png'\n",
    "    else:\n",
    "        raise RuntimeError('No file \"%s\" with extension png or jpg.' % path)\n",
    "\n",
    "def read_pairs(pairs_filename):\n",
    "    pairs = []\n",
    "    with open(pairs_filename, 'r') as f:\n",
    "        for line in f.readlines()[1:]:\n",
    "            pair = line.strip().split()\n",
    "            pairs.append(pair)\n",
    "    return np.array(pairs)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "from tensorflow.python.ops import data_flow_ops\n",
    "from sklearn import metrics\n",
    "from scipy.optimize import brentq\n",
    "from scipy import interpolate\n",
    "from yacs.config import CfgNode as CN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_args = CN()\n",
    "valid_args.lfw_dir            = 'Datasets/lfw/lfw_mtcnnpy_160/'\n",
    "valid_args.lfw_batch_size     = 100\n",
    "valid_args.model              = 'Pretrained/20180402-114759/'\n",
    "valid_args.image_size         = 160\n",
    "valid_args.lfw_pairs          = 'Datasets/lfw/pairs.txt'\n",
    "valid_args.lfw_nrof_folds     = 10\n",
    "valid_args.distance_metric    = 0 \n",
    "valid_args.use_flipped_images = True\n",
    "valid_args.subtract_mean      = True\n",
    "valid_args.use_fixed_image_standardization = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget http://vis-www.cs.umass.edu/lfw/pairs.txt -O Datasets/lfw/pairs.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "code_folding": [
     2,
     42
    ]
   },
   "outputs": [],
   "source": [
    "def validate_main(args):\n",
    "    with tf.Graph().as_default():\n",
    "        with tf.Session() as sess:\n",
    "            \n",
    "            # Read the file containing the pairs used for testing\n",
    "            pairs = read_pairs(os.path.expanduser(args.lfw_pairs))\n",
    "\n",
    "            # Get the paths for the corresponding images\n",
    "            paths, actual_issame = get_paths(os.path.expanduser(args.lfw_dir), pairs)\n",
    "            \n",
    "            image_paths_placeholder = tf.placeholder(tf.string, shape=(None,1), name='image_paths')\n",
    "            labels_placeholder = tf.placeholder(tf.int32, shape=(None,1), name='labels')\n",
    "            batch_size_placeholder = tf.placeholder(tf.int32, name='batch_size')\n",
    "            control_placeholder = tf.placeholder(tf.int32, shape=(None,1), name='control')\n",
    "            phase_train_placeholder = tf.placeholder(tf.bool, name='phase_train')\n",
    "            \n",
    "            nrof_preprocess_threads = 4\n",
    "            image_size = (args.image_size, args.image_size)\n",
    "            eval_input_queue = data_flow_ops.FIFOQueue(capacity=2000000,\n",
    "                                        dtypes=[tf.string, tf.int32, tf.int32],\n",
    "                                        shapes=[(1,), (1,), (1,)],\n",
    "                                        shared_name=None, name=None)\n",
    "            eval_enqueue_op = eval_input_queue.enqueue_many([image_paths_placeholder, labels_placeholder, control_placeholder], name='eval_enqueue_op')\n",
    "            image_batch, label_batch = create_input_pipeline(eval_input_queue, image_size, nrof_preprocess_threads, batch_size_placeholder)\n",
    "            \n",
    "            # Load the model\n",
    "            input_map = {'image_batch': image_batch, 'label_batch': label_batch, 'phase_train': phase_train_placeholder}\n",
    "            load_model(args.model, input_map=input_map)\n",
    "\n",
    "            # Get output tensor\n",
    "            embeddings = tf.get_default_graph().get_tensor_by_name(\"embeddings:0\")\n",
    "#              \n",
    "            coord = tf.train.Coordinator()\n",
    "            tf.train.start_queue_runners(coord=coord, sess=sess)\n",
    "\n",
    "            evaluate(sess, eval_enqueue_op, image_paths_placeholder, labels_placeholder, phase_train_placeholder, batch_size_placeholder, control_placeholder,\n",
    "                embeddings, label_batch, paths, actual_issame, args.lfw_batch_size, args.lfw_nrof_folds, args.distance_metric, args.subtract_mean,\n",
    "                args.use_flipped_images, args.use_fixed_image_standardization)\n",
    "def evaluate(sess, enqueue_op, image_paths_placeholder, labels_placeholder, phase_train_placeholder, batch_size_placeholder, control_placeholder,\n",
    "        embeddings, labels, image_paths, actual_issame, batch_size, nrof_folds, distance_metric, subtract_mean, use_flipped_images, use_fixed_image_standardization):\n",
    "    # Run forward pass to calculate embeddings\n",
    "    print('Runnning forward pass on LFW images')\n",
    "    \n",
    "    # Enqueue one epoch of image paths and labels\n",
    "    nrof_embeddings = len(actual_issame)*2  # nrof_pairs * nrof_images_per_pair\n",
    "    nrof_flips = 2 if use_flipped_images else 1\n",
    "    nrof_images = nrof_embeddings * nrof_flips\n",
    "    labels_array = np.expand_dims(np.arange(0,nrof_images),1)\n",
    "    image_paths_array = np.expand_dims(np.repeat(np.array(image_paths),nrof_flips),1)\n",
    "    control_array = np.zeros_like(labels_array, np.int32)\n",
    "    if use_fixed_image_standardization:\n",
    "        control_array += np.ones_like(labels_array)*FIXED_STANDARDIZATION\n",
    "    if use_flipped_images:\n",
    "        # Flip every second image\n",
    "        control_array += (labels_array % 2)*FLIP\n",
    "    sess.run(enqueue_op, {image_paths_placeholder: image_paths_array, labels_placeholder: labels_array, control_placeholder: control_array})\n",
    "    \n",
    "    embedding_size = int(embeddings.get_shape()[1])\n",
    "    assert nrof_images % batch_size == 0, 'The number of LFW images must be an integer multiple of the LFW batch size'\n",
    "    nrof_batches = nrof_images // batch_size\n",
    "    emb_array = np.zeros((nrof_images, embedding_size))\n",
    "    lab_array = np.zeros((nrof_images,))\n",
    "    for i in range(nrof_batches):\n",
    "        feed_dict = {phase_train_placeholder:False, batch_size_placeholder:batch_size}\n",
    "        emb, lab = sess.run([embeddings, labels], feed_dict=feed_dict)\n",
    "        lab_array[lab] = lab\n",
    "        emb_array[lab, :] = emb\n",
    "        if i % 10 == 9:\n",
    "            print('.', end='')\n",
    "            sys.stdout.flush()\n",
    "    print('')\n",
    "    embeddings = np.zeros((nrof_embeddings, embedding_size*nrof_flips))\n",
    "    if use_flipped_images:\n",
    "        # Concatenate embeddings for flipped and non flipped version of the images\n",
    "        embeddings[:,:embedding_size] = emb_array[0::2,:]\n",
    "        embeddings[:,embedding_size:] = emb_array[1::2,:]\n",
    "    else:\n",
    "        embeddings = emb_array\n",
    "\n",
    "    assert np.array_equal(lab_array, np.arange(nrof_images))==True, 'Wrong labels used for evaluation, possibly caused by training examples left in the input pipeline'\n",
    "    tpr, fpr, accuracy, val, val_std, far = lfw_evaluate(embeddings, actual_issame, nrof_folds=nrof_folds, distance_metric=distance_metric, subtract_mean=subtract_mean)\n",
    "    \n",
    "    print('Accuracy: %2.5f+-%2.5f' % (np.mean(accuracy), np.std(accuracy)))\n",
    "    print('Validation rate: %2.5f+-%2.5f @ FAR=%2.5f' % (val, val_std, far))\n",
    "    \n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    print('Area Under Curve (AUC): %1.3f' % auc)\n",
    "#     eer = brentq(lambda x: 1. - x - interpolate.interp1d(fpr, tpr)(x), 0., 1.)\n",
    "#     print('Equal Error Rate (EER): %1.3f' % eer)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate_main(valid_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
